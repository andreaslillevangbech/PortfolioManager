{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from src.constants import *\n",
    "from src.data.poloniex import Poloniex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-20 19:09:26\n",
      "2020-01-20 11:09:26\n"
     ]
    }
   ],
   "source": [
    "t = datetime(2020, 1, 20, 11, 9, 26)\n",
    "t = int(time.mktime(t.timetuple()))\n",
    "\n",
    "print(pd.to_datetime(t, unit='s'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-20 11:20:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 1, 20, 3, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minute = 60\n",
    "five_minutes = 5*minute\n",
    "\n",
    "polo = Poloniex()\n",
    "\n",
    "start = datetime(2020, 1, 20, 3, 9)\n",
    "start = int(time.mktime(start.timetuple()))\n",
    "\n",
    "end= datetime(2020, 1, 20, 3, 20)\n",
    "end= int(time.mktime(end.timetuple()))\n",
    "print(pd.to_datetime(end, unit='s'))\n",
    "datetime.fromtimestamp(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 224,\n",
       " 'last': '11769.16394365',\n",
       " 'lowestAsk': '11775.93412391',\n",
       " 'highestBid': '11772.10724296',\n",
       " 'percentChange': '-0.01281966',\n",
       " 'baseVolume': '1805522.06740540',\n",
       " 'quoteVolume': '152.33032802',\n",
       " 'isFrozen': '0',\n",
       " 'high24hr': '12089.27602694',\n",
       " 'low24hr': '11619.34350173'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tick = polo.marketTicker()\n",
    "tick['USDC_BTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-20 11:09:00', '2020-01-20 11:14:00',\n",
       "               '2020-01-20 11:19:00'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(list(range(start, end+1, 300)),unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = polo.marketChart(period=five_minutes, start=start, end=end, pair = 'USDC_BTC')\n",
    "for i in chart:\n",
    "    print(i)\n",
    "\n",
    "print(len(chart))\n",
    "\n",
    "first = chart[0]['date']\n",
    "print(pd.to_datetime(start))\n",
    "print(pd.to_datetime(first))\n",
    "\n",
    "last = chart[-1]['date']\n",
    "print(pd.to_datetime(end))\n",
    "print(pd.to_datetime(last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randint(1,10, (5*2, 3))\n",
    "arrays = [['red', 'blue','btc', 'eth', 'snx'], [i for i in range(2)]]\n",
    "index = pd.MultiIndex.from_product(arrays)\n",
    "df = pd.DataFrame(data, index = index, columns=['open', 'close', 'vol'])\n",
    "print(df)\n",
    "df.values.reshape(5,2,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "now = int(time.time())\n",
    "time_index = pd.to_datetime(list(range(now - 300*10, now, 300)),unit='s')\n",
    "time_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = pd.Panel(items=[1,2,3,4], major_axis=arrays[1], minor_axis=arrays[0], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need an alternative to Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cash(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Cash, self).__init__()\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(5, activation='relu')\n",
    " \n",
    "        self.b = tf.Variable(tf.zeros((1, 1), dtype=tf.float32), trainable=True)\n",
    "        self.out = tf.keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense(x)\n",
    "        bias = tf.tile(self.b, [tf.shape(x)[0], 1])\n",
    "        x = tf.concat((bias, x), axis = -1)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "model = Cash()\n",
    "\n",
    "X = np.random.randn(100, 3)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = model(X)\n",
    "\n",
    "print([var.name for var in tape.watched_variables()])\n",
    "grads = tape.gradient(y, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cash(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, rows = 11, cols = 50, features = 3):\n",
    "        super(Cash, self).__init__()\n",
    "        \n",
    "        input_shape = (rows, cols, features)\n",
    "        inputs = tf.keras.Input(shape=input_shape)\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters = 2, \n",
    "            kernel_size = (1,3), \n",
    "            padding='valid', \n",
    "            activation='relu',\n",
    "            name = 'conv1'\n",
    "        )(inputs)\n",
    "        x = tf.keras.layers.Conv2D(1, \n",
    "                                (1, x.shape[2]), \n",
    "                                activation=\"relu\", \n",
    "                                name = 'conv2')(x)\n",
    "        x = tf.squeeze(x)\n",
    "        \n",
    "        self.model = tf.keras.Model(inputs = inputs, outputs = x)\n",
    "        \n",
    "        self.b = tf.Variable(tf.zeros((1, 1), dtype=tf.float32), trainable=True)\n",
    "        self.out = tf.keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.model(x)\n",
    "        print(x.shape)\n",
    "        bias = tf.tile(self.b, [tf.shape(x)[0], 1])\n",
    "        x = tf.concat((bias, x), axis = -1)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "model = Cash()\n",
    "\n",
    "X = np.random.randn(100, 11, 50, 3)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = model(X)\n",
    "\n",
    "print([var.name for var in tape.watched_variables()])\n",
    "grads = tape.gradient(y, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 100\n",
    "dense = tf.keras.layers.Dense(5, activation='relu')\n",
    "b = tf.Variable(tf.zeros((1,1), dtype=tf.float32), name='b', trainable=True)\n",
    "\n",
    "x =  tf.random.normal((batch, 3))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = dense(x)\n",
    "    cash = tf.tile(b, [y.shape[0], 1])\n",
    "    y = tf.concat((cash, y), axis = -1)\n",
    "    y = tf.keras.layers.Activation('softmax')(y)\n",
    "\n",
    "print([var.name for var in tape.watched_variables()])\n",
    "grads = tape.gradient(y, [b, dense.trainable_variables])\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(rows, cols, features, batch_size):\n",
    "    input_shape = (rows, cols, features)\n",
    "    X = keras.Input(shape= input_shape, batch_size=batch_size)\n",
    "    w = keras.Input(shape = (rows, 1, 1), batch_size=batch_size)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters = 2, \n",
    "        kernel_size = (1,3), \n",
    "        padding='valid', \n",
    "        activation='relu'\n",
    "    )(X)\n",
    "        \n",
    "    x = keras.layers.Conv2D(20, \n",
    "                            (1, x.shape[2]), \n",
    "                            activation=\"relu\", \n",
    "                            name = 'conv2')(x)  \n",
    "    \n",
    "    con = keras.layers.Concatenate(axis=3)([x, w])\n",
    "\n",
    "    x = keras.layers.Conv2D(1, (1,1), name = 'votes')(con)\n",
    "    x = tf.squeeze(x)\n",
    "    \n",
    "    b = tf.tile(b, [x.shape[0], 1])\n",
    "    with_bias = keras.layers.Concatenate(axis=1)([b, x])\n",
    "    #with_bias = CashBias()(x)\n",
    "\n",
    "    outputs = keras.layers.Activation('softmax')(with_bias)\n",
    "    return keras.Model(inputs = [X, w], outputs = outputs, name = \"Policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training dataset.\n",
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = np.reshape(x_train, (-1, 784))\n",
    "x_test = np.reshape(x_train, (-1, 784))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in train_dataset:\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Run the forward pass of the layer.\n",
    "        # The operations that the layer applies\n",
    "        # to its inputs are going to be recorded\n",
    "        # on the GradientTape.\n",
    "        logits = model(x, training=True)  # Logits for this minibatch\n",
    "\n",
    "        # Compute the loss value for this minibatch.\n",
    "        loss_value = loss_fn(y, logits)\n",
    "\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss.\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    # optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    shapes = [grad.shape for grad in grads]\n",
    "    print(shapes)\n",
    "    print(model.trainable_variables)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [np.random.rand(2,3) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(a, dtype='float32').dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
